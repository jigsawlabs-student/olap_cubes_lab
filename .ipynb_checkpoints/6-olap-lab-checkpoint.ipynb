{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "nominated-native",
   "metadata": {},
   "source": [
    "# Constructing OLAP cubes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ultimate-scheduling",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "younger-banana",
   "metadata": {},
   "source": [
    "In this lesson, we'll practice using SQL queries to construct our OLAP cubes.  We'll work up towards construct the query for the movie rental database that we've used previously. Let's get started."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "robust-fiber",
   "metadata": {},
   "source": [
    "### Getting Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "important-brother",
   "metadata": {},
   "source": [
    "Now we have previously used the movie database in an OLTP structure, but in this lesson, we'll need to also create the tables for a star schema, and copy over our data into that structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "insured-winning",
   "metadata": {},
   "source": [
    "* To do this, uncomment and run the command below to create the `pagila_starred` database in postgres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "subtle-comment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !PGPASSWORD=postgres createdb -h 127.0.0.1 -U postgres pagila_starred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "several-finnish",
   "metadata": {},
   "source": [
    "* And then uncomment and run the command below to create the tables and load in the corresponding data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fourth-airfare",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !PGPASSWORD=postgres psql -q -h 127.0.0.1 -U postgres -d pagila_starred -f data/pagila_star.sql"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleased-headset",
   "metadata": {},
   "source": [
    "Then we'll declare the following function to connect to the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "living-firmware",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "def get_cursor():\n",
    "    conn = psycopg2.connect(\n",
    "    host=\"127.0.0.1\",\n",
    "    database=\"pagila_starred\",\n",
    "    user=\"postgres\",\n",
    "    password=\"postgres\")\n",
    "    cursor = conn.cursor()\n",
    "    return cursor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "julian-vehicle",
   "metadata": {},
   "source": [
    "Ok, next create the cursor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "frozen-rotation",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = get_cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detected-spouse",
   "metadata": {},
   "source": [
    "And then we can begin to explore the database.  \n",
    "\n",
    "So log into postgres, connect to the database, and get a sense of the different tables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developed-oliver",
   "metadata": {},
   "source": [
    "> <img src=\"./pagila_relations.png\" width=\"40%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exceptional-colleague",
   "metadata": {},
   "source": [
    "If you look at the database, we can see that while we have multiple tables in the database, only the ones beginning with `dim` or `fact` are meant for our OLAP.\n",
    "\n",
    "Now take a look at the columns in the fact table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dynamic-criticism",
   "metadata": {},
   "source": [
    "> <img src=\"./factsales.png\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expanded-constant",
   "metadata": {},
   "source": [
    "And let's take a look at one of the dimension tables, say the `dimmovie` columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seasonal-register",
   "metadata": {},
   "source": [
    "> <img src=\"./dimmovie.png\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coastal-victim",
   "metadata": {},
   "source": [
    "> **Note**:  We can see that the dimension table has a primary key of `movie_key`, instead of our typical `id` column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quality-salvation",
   "metadata": {},
   "source": [
    "Overall, our star schema takes on the same form that we have seen previously. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatty-label",
   "metadata": {},
   "source": [
    "<img src=\"./star_schemad_movies.png\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposite-butter",
   "metadata": {},
   "source": [
    "With this structure in mind, let's begin to make our queries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charitable-compact",
   "metadata": {},
   "source": [
    "### Making the queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "popular-sheep",
   "metadata": {},
   "source": [
    "So instead diving right into the query for an OLAP cube, let's instead build up to it.\n",
    "\n",
    "1. Begin by finding the number of sales made in each movie rating category -- order from highest to lower by number of sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "royal-mississippi",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "friendly-electric",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "native-plaintiff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PG-13', 3585), ('NC-17', 3298), ('PG', 3212), ('R', 3181), ('G', 2773)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.fetchall()\n",
    "# [('PG-13', 3585), ('NC-17', 3298), ('PG', 3212), ('R', 3181), ('G', 2773)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocal-exchange",
   "metadata": {},
   "source": [
    "So we can see that the most popular movies were PG-13, and the least popular were rated G."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "devoted-coating",
   "metadata": {},
   "source": [
    "2. Next, group the data by store number and rating -- showing the number of sales made across both dimensions.\n",
    "\n",
    "> So this would be the equivalent of the following diagram (the answers will differ)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medium-utilization",
   "metadata": {},
   "source": [
    "> <img src=\"./two_dim_group.png\" width=\"30%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contemporary-drive",
   "metadata": {},
   "source": [
    "To accomplish this, we will need to group by multiple columns.  If unsure how to group by multiple columns, see the [following post](https://stackoverflow.com/questions/2421388/using-group-by-on-multiple-columns). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitting-actor",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "cursor.execute(query)\n",
    "agg_sales = cursor.fetchall()\n",
    "agg_sales\n",
    "\n",
    "\n",
    "# [('PG-13', 1, 1849),\n",
    "#  ('PG-13', 2, 1736),\n",
    "#  ('PG', 2, 1677),\n",
    "#  ('NC-17', 2, 1668),\n",
    "#  ('R', 2, 1644),\n",
    "#  ('NC-17', 1, 1630),\n",
    "#  ('R', 1, 1537),\n",
    "#  ('PG', 1, 1535),\n",
    "#  ('G', 2, 1396),\n",
    "#  ('G', 1, 1377)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alleged-digest",
   "metadata": {},
   "source": [
    "So above, we can see that our sales are divided across two dimensions: the rating and the store.  And we show the total sales broken out for each.  \n",
    "\n",
    "> Now we can use some pandas to make it easier to view the results.  It's not important that you understand the below queries at this point.  We'll go through this later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "invalid-begin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>G</th>\n",
       "      <td>1377</td>\n",
       "      <td>1396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NC-17</th>\n",
       "      <td>1630</td>\n",
       "      <td>1668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PG</th>\n",
       "      <td>1535</td>\n",
       "      <td>1677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PG-13</th>\n",
       "      <td>1849</td>\n",
       "      <td>1736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R</th>\n",
       "      <td>1537</td>\n",
       "      <td>1644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "1         1     2\n",
       "0                \n",
       "G      1377  1396\n",
       "NC-17  1630  1668\n",
       "PG     1535  1677\n",
       "PG-13  1849  1736\n",
       "R      1537  1644"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "sales_df = pd.DataFrame(agg_sales)\n",
    "sales_df.pivot_table(values=2, \n",
    "                     index=sales_df[0],\n",
    "                     columns=sales_df[1],\n",
    "                     aggfunc='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocational-winner",
   "metadata": {},
   "source": [
    "So as we can see, this is turning into a nice little dashboard.  Sales by store are along the horizontal axis, and sales by rating are along the vertical axis.  So currently we have the \"what\" on the y axis, and the \"where\" along the x axis.  Let's add in the \"when\" along the z axis.  To do so, we'll add to our previous query by grouping by year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "lined-still",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "quarterly-dispatch",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "another-gospel",
   "metadata": {},
   "outputs": [],
   "source": [
    "cubed_results = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "serial-payday",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, 'PG-13', 1, 797),\n",
       " (4, 'PG-13', 2, 727),\n",
       " (4, 'PG', 2, 704),\n",
       " (4, 'NC-17', 2, 690),\n",
       " (4, 'R', 2, 679),\n",
       " (4, 'NC-17', 1, 666),\n",
       " (4, 'PG', 1, 651),\n",
       " (4, 'R', 1, 643),\n",
       " (3, 'PG-13', 1, 635),\n",
       " (3, 'NC-17', 2, 609)]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cubed_results\n",
    "\n",
    "# [(4, 'PG-13', 1, 797),\n",
    "#  (4, 'PG-13', 2, 727),\n",
    "#  (4, 'PG', 2, 704),\n",
    "#  (4, 'NC-17', 2, 690),\n",
    "#  (4, 'R', 2, 679),\n",
    "#  (4, 'NC-17', 1, 666),\n",
    "#  (4, 'PG', 1, 651),\n",
    "#  (4, 'R', 1, 643),\n",
    "#  (3, 'PG-13', 1, 635),\n",
    "#  (3, 'NC-17', 2, 609)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "healthy-hunger",
   "metadata": {},
   "source": [
    "One of the things we can notice is that the only sales that exists for March are PG-13 and NC-17 movies.  So this may explain at least part of the disproportionate sales of those movies  -- it looks like the rest of the sales data is missing.  Either way by breaking this data out across three dimensions, we were able to better spot some anomalies in our data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crucial-industry",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tracked-avatar",
   "metadata": {},
   "source": [
    "In this lesson, we saw how to construct the queries for our OLAP cubes.  We did so by joining together the required tables, and then by grouping our data across various dimensions.  As we saw, doing so allowed us to view aggregated information across multiple dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "linear-miniature",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "[Crosstab function](https://learnsql.com/blog/creating-pivot-tables-in-postgresql-using-the-crosstab-function/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
